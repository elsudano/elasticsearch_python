{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ElasticSearch & Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conceptos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elasticsearch sistema de almacenamiento que permite indexar y analizar en tiempo real grandes cantidades de datos.\n",
    "Actúa como repositorio de información, almacenando los documentos que indexa para su rápida búsqueda.\n",
    " **No necesita declarar un esquema** de la información que añadimos, aunque pero para sacar mayor partido a la información tendremos que añadir los llamados **mapping**.\n",
    "\n",
    "- OpenSource\n",
    "- Escrito en Java\n",
    "- Apache Lucene\n",
    "- Permite Arquitectura: distribuida.\n",
    "- Escalable, en alta disponibilidad.\n",
    "- Útil para soluciones NoSQL (sin transacciones distribuidas).\n",
    "- API RESTfull sobre http para consulta, indexación, administración.\n",
    "- Permite alias de índices\n",
    "- Permite consultas sobre uno o varios índices\n",
    "- Full Text Search o búsqueda por texto completo\n",
    "- Indexa todos los campos de los documentos JSON.\n",
    "- Búsquedas mediante ElasticSearch Query DSL (Domain Specific Language): multilenguaje, geolocalización, contextual, autocompletar, etc\n",
    "\n",
    "Su RESTful API permite cualquier integración con otras tecnologías."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traducción de los conceptos a lenguage relacional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Relationnal database | Elasticsearch         |\n",
    "|----------------------|-----------------------|\n",
    "| Database             | Index                 |\n",
    "| Table                | Type                  |\n",
    "| Row                  | Document              |\n",
    "| Column               | Field                 |\n",
    "| Schema               | Mapping               |\n",
    "| Index                | Everything is indexed |\n",
    "| SQL                  | Query DSL             |\n",
    "| SELECT * FROM table… | GET http://…          |\n",
    "| UPDATE table SET     | PUT http://…          |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elasticsearch Analyser,  term frecuency y index term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](/home/docker_worker/work/assert/analyzer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/analyser.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Elasticsearch([{'host': 'elasticsearch'}])>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch_dsl import connections\n",
    "\n",
    "connections.create_connection(hosts=['elasticsearch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yellow\n"
     ]
    }
   ],
   "source": [
    "print(connections.get_connection().cluster.health()['status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from elasticsearch_dsl import Document, Date, Integer, Keyword, Text\n",
    "from elasticsearch_dsl.connections import connections\n",
    "\n",
    "\n",
    "class Article(Document):\n",
    "    title = Text(analyzer='snowball', fields={'raw': Keyword()})\n",
    "    body = Text(analyzer='snowball')\n",
    "    tags = Keyword()\n",
    "    published_from = Date()\n",
    "    words = Integer()\n",
    "\n",
    "    class Index:\n",
    "        name = 'blog'\n",
    "        settings = {\n",
    "          \"number_of_shards\": 2,\n",
    "        }\n",
    "\n",
    "    def save(self, ** kwargs):\n",
    "        self.words = len(self.body.split())\n",
    "        return super(Article, self).save(** kwargs)\n",
    "\n",
    "    def is_published(self):\n",
    "        return datetime.now() >= self.published_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import elasticsearch.exceptions as elasticexceptions\n",
    "from elasticsearch_dsl import Index\n",
    "\n",
    "index = Index(\"blog\")\n",
    "\n",
    "try:\n",
    "    index.delete()\n",
    "except elasticexceptions.NotFoundError:\n",
    "    pass\n",
    "\n",
    "Article.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article1 = Article(title='Hello world!', tags=['test'])\n",
    "article1.body = ''' Lorem ipsum dolor sit amet, consectetur adipiscing elit. Ut magna augue, congue eget vulputate id, vestibulum ut augue. Sed accumsan at diam ut consectetur. Nam sed massa ac libero lobortis sodales ac eu justo. Cras lacus ipsum, lobortis et porttitor vehicula, congue vitae lacus. Maecenas pharetra justo risus, eu ultrices risus sollicitudin eu. Orci varius natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Donec ac est ultrices, congue odio ac, faucibus nisi. Nullam eu nibh ut ligula rutrum ullamcorper vitae ac diam. '''\n",
    "article1.published_from = datetime.now()\n",
    "article1.save()\n",
    "\n",
    "article2 = Article(title='Bye world!', tags=['test'])\n",
    "article2.body = ''' Vivamus eu ipsum neque. Nullam eget congue tortor, ut blandit dui. Proin eu ultrices sem. Phasellus tellus sem, egestas vitae ullamcorper sit amet, sollicitudin non velit. Aenean vel neque nec tellus semper ultricies eget sed ex. Aliquam porttitor eu eros non gravida. Nulla eu ligula dapibus, eleifend nisl ac, consectetur massa. Ut vitae dolor felis. Praesent sit amet est sit amet dui sagittis iaculis. Orci varius natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Curabitur orci libero, dictum nec ex vitae, accumsan pellentesque nisi. '''\n",
    "article2.published_from = datetime.now()\n",
    "article2.save()\n",
    "\n",
    "article3 = Article(title='Other world!', tags=['awesome'])\n",
    "article3.body = ''' Curabitur rutrum arcu nec cursus viverra. Maecenas gravida pellentesque erat, id semper leo rutrum sed. Proin faucibus lectus eu libero sagittis pulvinar.'''\n",
    "article3.published_from = datetime.now()\n",
    "article3.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = Article.search().query(\"match\", body=\"adipiscing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': {'match': {'body': 'adipiscing'}}}\n"
     ]
    }
   ],
   "source": [
    "print(search.to_dict())\n",
    "response = search.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world!  84\n"
     ]
    }
   ],
   "source": [
    "result = [print(f\"{hit.title}  {hit.words}\") for hit in search]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bye world!  86\n"
     ]
    }
   ],
   "source": [
    "search = Article.search().query(\"match\", body=\"tortor\")\n",
    "response = search.execute()\n",
    "result = [print(f\"{hit.title}  {hit.words}\") for hit in search]    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': {'match': {'body': 'ipsum'}}, 'sort': [{'words': {'order': 'desc'}}]}\n",
      "\n",
      "Bye world!  86\n",
      "Hello world!  84\n"
     ]
    }
   ],
   "source": [
    "search = Article.search().query(\"match\", body=\"ipsum\").sort('-words')\n",
    "\n",
    "print(search.to_dict())\n",
    "print()\n",
    "\n",
    "response = search.execute()\n",
    "result = [print(f\"{hit.title}  {hit.words}\") for hit in search]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': {'bool': {'filter': [{'terms': {'tags': ['awesome']}}]}}}\n",
      "\n",
      "Other world!  22\n"
     ]
    }
   ],
   "source": [
    "search = Article.search().filter('terms', tags=['awesome'])\n",
    "\n",
    "print(search.to_dict())\n",
    "print()\n",
    "\n",
    "response = search.execute()\n",
    "result = [print(f\"{hit.title}  {hit.words}\") for hit in search]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import helpers, Elasticsearch\n",
    "import csv\n",
    "\n",
    "#es = Elasticsearch()\n",
    "\n",
    "with open('/home/docker_worker/work/data/titanic.csv') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    #helpers.bulk(es, reader, index='my-index', doc_type='my-type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch_dsl import Document, Date, Integer, Keyword, Text, Boolean, Float\n",
    "\n",
    "class TitanicPassenger(Document):\n",
    "    passengerid = Integer()\n",
    "    survived = Integer()\n",
    "    pclass = Integer()\n",
    "    name = Text(analyzer='snowball')\n",
    "    sex = Keyword()\n",
    "    age = Integer()\n",
    "    sibsp = Integer()\n",
    "    parch = Integer()\n",
    "    ticket = Keyword()\n",
    "    fare = Float()\n",
    "    cabin = Keyword()\n",
    "    embarked = Keyword()\n",
    "    \n",
    "\n",
    "    class Index:\n",
    "        name = 'titanic'\n",
    "        settings = {\n",
    "          \"number_of_shards\": 2,\n",
    "          \"blocks\":{'read_only_allow_delete': None},\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import elasticsearch.exceptions as elasticexceptions\n",
    "from elasticsearch_dsl import Index\n",
    "\n",
    "index = Index(\"titanic\")\n",
    "\n",
    "try:\n",
    "    index.delete()\n",
    "except elasticexceptions.NotFoundError:\n",
    "    pass\n",
    "\n",
    "TitanicPassenger.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path='/home/docker_worker/work/data/titanic.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passengerid</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley</td>\n",
       "      <td>female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7925.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath</td>\n",
       "      <td>female</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passengerid  survived  pclass                          name     sex  age  \\\n",
       "0            1         0       3       Braund, Mr. Owen Harris    male   22   \n",
       "1            2         1       1    Cumings, Mrs. John Bradley  female   38   \n",
       "2            3         1       3        Heikkinen, Miss. Laina  female   26   \n",
       "3            4         1       1  Futrelle, Mrs. Jacques Heath  female   35   \n",
       "4            5         0       3      Allen, Mr. William Henry    male   35   \n",
       "\n",
       "   sibsp  parch            ticket       fare cabin embarked  \n",
       "0      1      0         A/5 21171     7.2500   NaN        S  \n",
       "1      1      0          PC 17599    71.2833   C85        C  \n",
       "2      0      0  STON/O2. 3101282  7925.0000   NaN        S  \n",
       "3      1      0            113803    53.1000  C123        S  \n",
       "4      0      0            373450     8.0500   NaN        S  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(csv_path, sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import helpers, Elasticsearch\n",
    "import csv\n",
    "es = Elasticsearch(\"elasticsearch:9200\")\n",
    "\n",
    "def docs_for_load():\n",
    "    with open(csv_path) as f:\n",
    "        reader = csv.reader(f, delimiter=\"\\t\")\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            TitanicPassenger(passengerid=row[0],\n",
    "                                   survived=row[1],\n",
    "                                   pclass=row[2],\n",
    "                                   name=row[3],\n",
    "                                   sex=row[4],\n",
    "                                   age=row[5],\n",
    "                                   sibsp=row[6],\n",
    "                                   parch=row[7],\n",
    "                                   ticket=row[8],\n",
    "                                   fare=row[9],\n",
    "                                   cabin=row[10],\n",
    "                                   embarked=row[11]).save()\n",
    "\n",
    "docs_for_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153) Meo, Mr. Alfonzo\n"
     ]
    }
   ],
   "source": [
    "search = TitanicPassenger.search().query(\"match\", name=\"Meo\")\n",
    "response = search.execute()\n",
    "result = [print(f\"{hit.passengerid}) {hit.name}\") for hit in search]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
